{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : 80.0 %\n",
      "Test set : 20.0 % \n",
      "\n",
      "Total number of touples:  1728\n",
      "Touples in training set:  1382\n",
      "Touples in testing set :  346 \n",
      "\n",
      "Confusion Matrix: \n",
      " Predicted \n",
      " ['unacc', 'acc', 'vgood', 'good'] \n",
      " [[240   1   0   1]\n",
      " [  9  68   0   0]\n",
      " [  0   3   9   1]\n",
      " [  2   6   0   6]] \n",
      "\n",
      "Accuracy:  93.35260115606935 % \n",
      "\n",
      "Recall for class :  unacc =  0.9917355371900827\n",
      "FP rate for class :  unacc =  0.10576923076923077\n",
      "Precision for class :  unacc =  0.9561752988047809\n",
      "F1 for class :  unacc =  0.973630831643002\n",
      "\n",
      "\n",
      "Recall for class :  acc =  0.8831168831168831\n",
      "FP rate for class :  acc =  0.03717472118959108\n",
      "Precision for class :  acc =  0.8717948717948718\n",
      "F1 for class :  acc =  0.8774193548387098\n",
      "\n",
      "\n",
      "Recall for class :  vgood =  0.6923076923076923\n",
      "FP rate for class :  vgood =  0.0\n",
      "Precision for class :  vgood =  1.0\n",
      "F1 for class :  vgood =  0.8181818181818181\n",
      "\n",
      "\n",
      "Recall for class :  good =  0.42857142857142855\n",
      "FP rate for class :  good =  0.006024096385542169\n",
      "Precision for class :  good =  0.75\n",
      "F1 for class :  good =  0.5454545454545454\n",
      "\n",
      "\n",
      "Training Time  0.005012000000007788\n",
      "Testing Time  0.0586571000000049\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.neighbors import KNeighborsClassifier as ks\n",
    "from sklearn import metrics as mtx\n",
    "from timeit import default_timer as timer\n",
    "k=5\n",
    "\n",
    "#enter as percentage \n",
    "testsize=20\n",
    "testsize=testsize/100\n",
    "print(\"Training set :\" ,(1-testsize)*100,\"%\")\n",
    "print(\"Test set :\",testsize*100,\"%\",\"\\n\")\n",
    "\n",
    "#importing dataset\n",
    "df=pd.read_csv('cars_dataset.csv')\n",
    "\n",
    "#dictionary for encoding attribute values\n",
    "encode_dictionary = {\"buying\":{\"vhigh\":1,\"high\":2,\"med\":3,\"low\":4},\n",
    "                     \"maint\":{\"vhigh\":1,\"high\":2,\"med\":3,\"low\":4},\n",
    "                     \"doors\":{\"two\":1,\"three\":2,\"four\":3,\"5more\":4},\n",
    "                     \"persons\":{\"two\":1,\"four\":2,\"more\":3},\n",
    "                     \"lug_boot\":{\"small\":1,\"med\":2,\"big\":3},\n",
    "                     \"safety\":{\"low\":1,\"med\":2,\"high\":3},\n",
    "                     \"car\":{\"unacc\":1,\"acc\":2,\"vgood\":3,\"good\":4} }\n",
    "#encoding using dictionary   \n",
    "df.replace(encode_dictionary,inplace=True)  \n",
    "\n",
    "\n",
    "#X is the dataset without class label\n",
    "X=df.drop(columns='car')\n",
    "\n",
    "\n",
    "#y contains all the class labels only\n",
    "y=df['car'].values\n",
    "\n",
    "\n",
    "#shuffled split\n",
    "X_train,X_test,y_train,y_test=tts(X,y,test_size=testsize,random_state=0,stratify=y)\n",
    "\n",
    "#maintain serial while splitting\n",
    "#X_train,X_test,y_train,y_test=tts(X,y,test_size=testsize,random_state=100,shuffle=False)\n",
    "#print(X_train)\n",
    "start=timer()\n",
    "knn=ks(n_neighbors = k )\n",
    "knn.fit(X_train,y_train)\n",
    "end=timer()\n",
    "\n",
    "train_time=end-start\n",
    "start=timer()\n",
    "#y_pred contains predicted class labels\n",
    "y_pred=knn.predict(X_test)\n",
    "#print(y_pred)\n",
    "end=timer()\n",
    "test_time=end-start\n",
    "\n",
    "print(\"Total number of touples: \",df.shape[0])\n",
    "print(\"Touples in training set: \",y_train.shape[0])\n",
    "print(\"Touples in testing set : \",y_test.shape[0],\"\\n\")\n",
    "\n",
    "#print(\"f1 score: \",mtx.f1_score(y_test,y_pred,average = None))\n",
    "\n",
    "\n",
    "#confusion matrix\n",
    "cm = mtx.confusion_matrix(y_test,y_pred,labels=[1,2,3,4])\n",
    "\n",
    "\n",
    "\n",
    "labels=['unacc','acc','vgood','good']\n",
    "print(\"Confusion Matrix:\",\"\\n\",\"Predicted\",\"\\n\",labels,\"\\n\",cm,\"\\n\")\n",
    "\n",
    "print(\"Accuracy: \",mtx.accuracy_score(y_test,y_pred)*100,'%',\"\\n\")\n",
    "\n",
    "#count number of row in training set\n",
    "testing=y_test.shape[0]\n",
    "\n",
    "for x in range (4):\n",
    "    recaldiv=0     #divisor for recall\n",
    "    precisiondiv=0 #divisor for precision\n",
    "    FPup=0         #numerator for false positive\n",
    "    FPdown= 0      #denominator for fp\n",
    "    \n",
    "    \n",
    "    for y in range (4) :\n",
    "        # add all element of the row of current class,actual number of element in class \n",
    "        # denoted by row x\n",
    "        recaldiv=recaldiv+cm[x][y]                  \n",
    "        precisiondiv=precisiondiv+cm[y][x] #add all element of column,all that has been predicted as current class\n",
    "        if x!=y :   #incorrect prediction,not in x,x position of a column\n",
    "            FPup=FPup+cm[y][x] \n",
    "            \n",
    "            \n",
    "        \n",
    "    FPdown=testing-recaldiv #those that are actually false,all in cm except actually in current class (recaldiv)\n",
    "                             \n",
    "    \n",
    "    if cm[x][x] == 0 : #cm[x][x] is TP\n",
    "        recall=0\n",
    "        if precisiondiv == 0: \n",
    "            prec= \"?\"\n",
    "        else:\n",
    "            prec=0\n",
    "            \n",
    "        f1=\"?\"\n",
    "          \n",
    "    else: \n",
    "        \n",
    "        recall=cm[x][x]/recaldiv\n",
    "        FPrate=FPup/FPdown\n",
    "        prec=cm[x][x]/precisiondiv\n",
    "        f1=2*(recall*prec)/(recall+prec)\n",
    "    \n",
    "    print(\"Recall for class : \",labels[x],\"= \",recall)\n",
    "    print(\"FP rate for class : \",labels[x],\"= \",FPrate)\n",
    "    print(\"Precision for class : \",labels[x],\"= \",prec)\n",
    "    print(\"F1 for class : \",labels[x],\"= \",f1)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Training Time \",train_time)\n",
    "print(\"Testing Time \",test_time)\n",
    "#print(mtx.classification_report(y_test,y_pred))\n",
    "#knn.score(X_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
